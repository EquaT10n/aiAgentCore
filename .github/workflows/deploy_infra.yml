# 工作流名称：部署开发环境基础设施
name: deploy-infra-dev

# 触发条件：main 分支相关目录变更，或手动触发
on:
  push:
    branches: [ "main" ]
    # 仅当这些路径变化时才触发部署
    paths:
      - "infra/**"
      - "src/agent/**"
      - "scripts/**"
      - "buildspec-*.yml"
      - "cicd/**"
      - ".github/workflows/deploy_infra.yml"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    # 最小权限原则：只开本作业必需权限
    permissions:
      # OIDC 交换 AWS 临时凭证
      id-token: write
      # checkout 需要读取仓库内容
      contents: read

    steps:
      # 拉取代码
      - uses: actions/checkout@v4

      # 安装 Python
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 安装 Node（CDK CLI 依赖）
      - uses: actions/setup-node@v4
        with:
          node-version: "20"

      # 安装 lint/test/CDK 工具链
      - name: Install toolchain
        run: |
          pip install -U pip ruff pytest
          pip install -e .
          npm i -g aws-cdk

      # 部署前先过质量门禁
      - name: Lint & Test
        run: |
          ruff check .
          pytest -q

      # 通过 GitHub OIDC 扮演 AWS Role
      - name: Assume AWS role via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::765936999892:role/GitHubActions-Deploy-InfraRole
          aws-region: ap-northeast-1

      # 确保 ECR 仓库存在，并输出仓库信息给后续步骤
      - name: Resolve ECR repository
        id: ecr
        env:
          AWS_REGION: ap-northeast-1
        run: |
          set -euo pipefail
          REPO_NAME="ai-agentcore-runtime"
          if ! aws ecr describe-repositories --repository-names "${REPO_NAME}" >/dev/null 2>&1; then
            aws ecr create-repository --repository-name "${REPO_NAME}" >/dev/null
          fi
          ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
          REPO_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPO_NAME}"
          echo "repo_name=${REPO_NAME}" >> "${GITHUB_OUTPUT}"
          echo "repo_uri=${REPO_URI}" >> "${GITHUB_OUTPUT}"

      # 启用 Buildx（支持多架构构建）
      - name: Configure Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 启用 QEMU（在 x86 runner 上执行 arm64 容器）
      - name: Configure QEMU
        uses: docker/setup-qemu-action@v3

      # 登录 Amazon ECR
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # 构建并推送 ARM64 运行时镜像
      - name: Build and push runtime image (linux/arm64)
        id: build
        env:
          # run_id + attempt 确保重跑也产生新 tag
          IMAGE_TAG: ${{ github.sha }}-${{ github.run_id }}-${{ github.run_attempt }}
        run: |
          set -euo pipefail
          docker buildx build \
            --platform linux/arm64 \
            --pull \
            --file src/agent/Dockerfile \
            --tag "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}" \
            --load \
            src/agent
          # 推送前做一次依赖自检，避免坏镜像进入仓库
          docker run --rm --platform linux/arm64 "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}" \
            python -c "import boto3, reportlab; print('deps_ok', boto3.__version__)"
          docker push "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}"
          IMAGE_REF="$(docker image inspect --format='{{index .RepoDigests 0}}' "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}")"
          echo "image_ref=${IMAGE_REF}" >> "${GITHUB_OUTPUT}"
          echo "Built image ref: ${IMAGE_REF}"
          echo "image_tag=${IMAGE_TAG}" >> "${GITHUB_OUTPUT}"

      # 使用 CDK 合成并部署基础设施
      - name: CDK Synth & Deploy
        env:
          MODEL_ID: ${{ vars.MODEL_ID }}
          MODEL_ARN: ${{ vars.MODEL_ARN }}
          PDF_URL_EXPIRES: ${{ vars.PDF_URL_EXPIRES }}
        run: |
          set -euo pipefail
          cd infra
          python -m venv .venv
          source .venv/bin/activate
          pip install -r requirements.txt
          cdk synth \
            -c existing_ecr_repository_name=${{ steps.ecr.outputs.repo_name }} \
            -c runtime_image_tag=${{ steps.build.outputs.image_tag }} \
            -c runtime_image_ref="${{ steps.build.outputs.image_ref }}" \
            -c model_id="${MODEL_ID:-amazon.nova-lite-v1:0}" \
            -c model_arn="${MODEL_ARN:-}" \
            -c pdf_url_expires="${PDF_URL_EXPIRES:-600}"
          cdk deploy --all --require-approval never \
            -c existing_ecr_repository_name=${{ steps.ecr.outputs.repo_name }} \
            -c runtime_image_tag=${{ steps.build.outputs.image_tag }} \
            -c runtime_image_ref="${{ steps.build.outputs.image_ref }}" \
            -c model_id="${MODEL_ID:-amazon.nova-lite-v1:0}" \
            -c model_arn="${MODEL_ARN:-}" \
            -c pdf_url_expires="${PDF_URL_EXPIRES:-600}"

      # 给部署角色附加 smoke 调用权限（及诊断日志权限）
      - name: Grant smoke invoke permission to deploy role
        env:
          AWS_REGION: ap-northeast-1
          DEPLOY_ROLE_NAME: GitHubActions-Deploy-InfraRole
          BUILT_IMAGE_TAG: ${{ steps.build.outputs.image_tag }}
          BUILT_IMAGE_REF: ${{ steps.build.outputs.image_ref }}
        run: |
          set -euo pipefail
          echo "Smoke is validating runtime image tag: ${BUILT_IMAGE_TAG}"
          echo "Smoke is validating runtime image ref: ${BUILT_IMAGE_REF}"
          STACK_NAME="InfraStack"
          STACK_OUTPUTS="$(aws cloudformation describe-stacks --stack-name "${STACK_NAME}" --query "Stacks[0].Outputs" --output json)"
          STACK_RUNTIME_IMAGE_URI="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="RuntimeContainerImageUri") | .OutputValue' | head -n1)"
          echo "Stack RuntimeContainerImageUri: ${STACK_RUNTIME_IMAGE_URI}"
          RUNTIME_ARN="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeArn") | .OutputValue' | head -n1)"
          ENDPOINT_NAME="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeEndpointName") | .OutputValue' | head -n1)"
          if [ -z "${RUNTIME_ARN}" ] || [ "${RUNTIME_ARN}" = "None" ]; then
            echo "Missing required stack output: AgentRuntimeArn"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          if [ -z "${ENDPOINT_NAME}" ] || [ "${ENDPOINT_NAME}" = "None" ]; then
            echo "Missing required stack output: AgentRuntimeEndpointName"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          ENDPOINT_ARN="${RUNTIME_ARN}/runtime-endpoint/${ENDPOINT_NAME}"
          cat > policy.json <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "AllowInvokeAgentRuntimeSmoke",
                "Effect": "Allow",
                "Action": "bedrock-agentcore:InvokeAgentRuntime",
                "Resource": [
                  "${RUNTIME_ARN}",
                  "${ENDPOINT_ARN}",
                  "${RUNTIME_ARN}/runtime-endpoint/*"
                ]
              },
              {
                "Sid": "AllowReadCloudWatchLogsForSmokeDiagnostics",
                "Effect": "Allow",
                "Action": [
                  "logs:DescribeLogGroups",
                  "logs:DescribeLogStreams",
                  "logs:FilterLogEvents",
                  "logs:GetLogEvents"
                ],
                "Resource": "*"
              }
            ]
          }
          EOF
          aws iam put-role-policy \
            --role-name "${DEPLOY_ROLE_NAME}" \
            --policy-name "AllowInvokeAgentRuntimeSmoke" \
            --policy-document file://policy.json
          # IAM 权限传播可能有延迟
          sleep 10

      # 部署后做一次真实 /invocations 调用
      - name: Smoke test /invocations
        env:
          AWS_REGION: ap-northeast-1
        run: |
          set -euo pipefail
          STACK_NAME="InfraStack"
          STACK_OUTPUTS="$(aws cloudformation describe-stacks --stack-name "${STACK_NAME}" --query "Stacks[0].Outputs" --output json)"
          RUNTIME_ARN="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeArn") | .OutputValue' | head -n1)"
          ENDPOINT_NAME="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeEndpointName") | .OutputValue' | head -n1)"
          if [ -z "${RUNTIME_ARN}" ] || [ "${RUNTIME_ARN}" = "None" ] || [ -z "${ENDPOINT_NAME}" ] || [ "${ENDPOINT_NAME}" = "None" ]; then
            echo "Missing required stack outputs: AgentRuntimeArn or AgentRuntimeEndpointName"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          export RUNTIME_ARN ENDPOINT_NAME
          python - <<'PY'
          import io
          import json
          import os
          import sys
          import time
          from datetime import datetime, timedelta, timezone

          import boto3

          runtime_arn = os.environ["RUNTIME_ARN"]
          endpoint_name = os.environ["ENDPOINT_NAME"]
          region = os.environ["AWS_REGION"]
          payload = {
              "prompt": "smoke ping",
              "user_id": "gha",
              "session_id": "deploy-smoke",
              "locale": "zh-CN",
          }

          client = boto3.client("bedrock-agentcore", region_name=region)
          logs_client = boto3.client("logs", region_name=region)

          def dump_runtime_start_logs() -> None:
              now = datetime.now(timezone.utc)
              start_ms = int((now - timedelta(minutes=5)).timestamp() * 1000)
              end_ms = int(now.timestamp() * 1000)
              try:
                  groups = []
                  paginator = logs_client.get_paginator("describe_log_groups")
                  for page in paginator.paginate():
                      for g in page.get("logGroups", []):
                          name = g.get("logGroupName", "")
                          if (
                              "bedrock" in name.lower()
                              and ("agentcore" in name.lower() or "runtime" in name.lower())
                          ):
                              groups.append(name)
                  if not groups:
                      print("CloudWatch diagnostic: no matching Bedrock/AgentCore log groups found.")
                      return
                  print("CloudWatch diagnostic log groups:")
                  for name in groups[:20]:
                      print(f"  - {name}")
                  for group in groups[:5]:
                      try:
                          events = logs_client.filter_log_events(
                              logGroupName=group,
                              startTime=start_ms,
                              endTime=end_ms,
                              limit=200,
                          ).get("events", [])
                      except Exception as inner_exc:  # noqa: BLE001
                          print(f"CloudWatch diagnostic read failed for {group}: {inner_exc}")
                          continue
                      if not events:
                          continue
                      print(f"CloudWatch diagnostic recent events from {group}:")
                      for ev in events[-30:]:
                          msg = (ev.get("message", "") or "").strip()
                          if not msg:
                              continue
                          ts = ev.get("timestamp")
                          print(f"[{ts}] {msg}")
              except Exception as exc:  # noqa: BLE001
                  print(f"CloudWatch diagnostic failed: {exc}")

          def decode_response_blob(blob: object) -> dict:
              if isinstance(blob, (bytes, bytearray)):
                  raw = bytes(blob).decode("utf-8")
                  return json.loads(raw)
              if hasattr(blob, "read"):
                  raw = blob.read().decode("utf-8")
                  return json.loads(raw)
              if isinstance(blob, io.IOBase):
                  raw = blob.read().decode("utf-8")
                  return json.loads(raw)
              if hasattr(blob, "__iter__"):
                  chunks = []
                  for event in blob:
                      chunk = event.get("chunk") if isinstance(event, dict) else None
                      if isinstance(chunk, dict) and "bytes" in chunk:
                          chunks.append(chunk["bytes"])
                  if chunks:
                      raw = b"".join(chunks).decode("utf-8")
                      return json.loads(raw)
              if isinstance(blob, str):
                  return json.loads(blob)
              raise TypeError(f"Unsupported response payload type: {type(blob)!r}")

          last_error = None
          response_json = None
          for i in range(1, 7):
              try:
                  resp = client.invoke_agent_runtime(
                      agentRuntimeArn=runtime_arn,
                      qualifier=endpoint_name,
                      payload=json.dumps(payload, ensure_ascii=False).encode("utf-8"),
                      contentType="application/json",
                  )
                  response_json = decode_response_blob(resp.get("response"))
                  with open("response.json", "w", encoding="utf-8") as f:
                      json.dump(response_json, f, ensure_ascii=False)
                  break
              except Exception as exc:  # noqa: BLE001
                  last_error = exc
                  print(f"Smoke attempt {i} failed ({exc.__class__.__name__}): {exc}")
                  if i == 6:
                      dump_runtime_start_logs()
                      raise
                  time.sleep(10)

          if response_json is None:
              print(f"Smoke failed without response object, last error: {last_error}")
              sys.exit(1)

          body_obj = response_json.get("body", response_json)
          if isinstance(body_obj, str):
              body_obj = json.loads(body_obj)

          ok_status = ("statusCode" not in response_json) or (response_json.get("statusCode") == 200)
          required = bool(
              isinstance(body_obj, dict)
              and body_obj.get("record_id")
              and body_obj.get("answer")
              and isinstance(body_obj.get("pdf"), dict)
              and body_obj["pdf"].get("s3_key")
              and body_obj["pdf"].get("url")
          )
          if not (ok_status and required):
              print("Smoke response validation failed.")
              print(json.dumps(response_json, ensure_ascii=False, indent=2))
              sys.exit(1)
          PY
