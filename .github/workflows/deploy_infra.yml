# 工作流名称：部署开发环境基础设施
name: deploy-infra-dev

# 触发条件：main 分支有相关目录变更时触发
on:
  push:
    # 只监听 main 分支
    branches: [ "main" ]
    # 仅当这些路径变化时才运行，避免无关提交触发部署
    paths:
      - "infra/**"
      - "src/agent/**"
      - ".github/workflows/deploy_infra.yml"
  workflow_dispatch:

# 定义部署作业
jobs:
  deploy:
    # 使用 Ubuntu Runner 执行部署
    runs-on: ubuntu-latest
    # 最小权限原则：仅授予本作业需要的权限
    permissions:
      # 用于 OIDC 联邦登录 AWS（签发短期凭证）
      id-token: write
      # 读取仓库内容（checkout 需要）
      contents: read

    # 部署步骤（按顺序执行）
    steps:
      # 拉取代码
      - uses: actions/checkout@v4

      # 安装 Python 运行时
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 安装 Node.js（CDK CLI 依赖 Node）
      - uses: actions/setup-node@v4
        with:
          node-version: "20"

      # 安装 lint/test/CDK 工具链
      - name: Install toolchain
        run: |
          # 安装 Python 包管理和质量工具
          pip install -U pip ruff pytest
          # 安装当前项目（让 tests 可导入 src/agent 包）
          pip install -e .
          # 全局安装 AWS CDK CLI
          npm i -g aws-cdk

      # 部署前先过质量门禁
      - name: Lint & Test
        run: |
          # 代码静态检查
          ruff check .
          # 自动化测试
          pytest -q

      # 通过 GitHub OIDC 临时扮演 AWS 角色
      - name: Assume AWS role via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # 目标 IAM Role（需预先配置对 GitHub OIDC 的信任）
          role-to-assume: arn:aws:iam::765936999892:role/GitHubActions-Deploy-InfraRole
          # 默认操作区域
          aws-region: ap-northeast-1

      # 确保 ECR 仓库存在，并输出仓库信息给后续步骤
      - name: Resolve ECR repository
        # 为步骤设置 ID，便于后续通过 steps.ecr.outputs.* 读取输出
        id: ecr
        env:
          # 当前步骤用到的区域变量
          AWS_REGION: ap-northeast-1
        run: |
          # 失败即退出；未定义变量报错；管道中任一步失败都报错
          set -euo pipefail
          # 固定运行时镜像仓库名
          REPO_NAME="ai-agentcore-runtime"
          # 若仓库不存在则创建
          if ! aws ecr describe-repositories --repository-names "${REPO_NAME}" >/dev/null 2>&1; then
            aws ecr create-repository --repository-name "${REPO_NAME}" >/dev/null
          fi
          # 获取当前 AWS 账号 ID
          ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
          # 拼接完整 ECR URI（账号+区域+仓库名）
          REPO_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPO_NAME}"
          # 写入步骤输出：仓库名
          echo "repo_name=${REPO_NAME}" >> "${GITHUB_OUTPUT}"
          # 写入步骤输出：仓库 URI
          echo "repo_uri=${REPO_URI}" >> "${GITHUB_OUTPUT}"

      # 配置 Docker Buildx，支持多架构构建
      - name: Configure Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 安装 QEMU，允许在 x86 runner 上运行 arm64 容器做自检
      - name: Configure QEMU
        uses: docker/setup-qemu-action@v3

      # 登录 ECR，后续 docker push 才有权限
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # 构建并推送 ARM64 运行时镜像（AgentCore 当前要求 arm64）
      - name: Build and push runtime image (linux/arm64)
        # 步骤输出 ID
        id: build
        env:
          # 用 sha + run_id + run_attempt 作为镜像 tag，确保 rerun 也会触发 runtime 镜像更新
          IMAGE_TAG: ${{ github.sha }}-${{ github.run_id }}-${{ github.run_attempt }}
        run: |
          set -euo pipefail
          # 使用 buildx 构建并直接 push 到 ECR
          docker buildx build \
            --platform linux/arm64 \
            --pull \
            --file src/agent/Dockerfile \
            --tag "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}" \
            --load \
            src/agent
          # 在本地镜像上做依赖自检，避免部署后才暴露缺包问题
          docker run --rm --platform linux/arm64 "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}" \
            python -c "import boto3, reportlab; print('deps_ok', boto3.__version__)"
          # 自检通过后再推送到 ECR
          docker push "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}"
          IMAGE_REF="$(docker image inspect --format='{{index .RepoDigests 0}}' "${{ steps.ecr.outputs.repo_uri }}:${IMAGE_TAG}")"
          echo "image_ref=${IMAGE_REF}" >> "${GITHUB_OUTPUT}"
          echo "Built image ref: ${IMAGE_REF}"
          # 输出镜像 tag 给 CDK 部署步骤使用
          echo "image_tag=${IMAGE_TAG}" >> "${GITHUB_OUTPUT}"

      # 合成并部署 CDK 栈
      - name: CDK Synth & Deploy
        env:
          # 从 GitHub Actions 仓库变量读取模型 ID（可为空，脚本里有默认值）
          MODEL_ID: ${{ vars.MODEL_ID }}
          # 可选：指定模型 ARN（跨账号或特殊权限场景）
          MODEL_ARN: ${{ vars.MODEL_ARN }}
          # 预签名 URL 过期秒数
          PDF_URL_EXPIRES: ${{ vars.PDF_URL_EXPIRES }}
        run: |
          set -euo pipefail
          # 进入 CDK 项目目录
          cd infra
          # 创建隔离虚拟环境，避免污染系统环境
          python -m venv .venv
          # 激活虚拟环境（Linux Runner 语法）
          source .venv/bin/activate
          # 安装 CDK Python 依赖
          pip install -r requirements.txt
          # 先 synth，提前发现模板/上下文错误
          cdk synth \
            -c existing_ecr_repository_name=${{ steps.ecr.outputs.repo_name }} \
            -c runtime_image_tag=${{ steps.build.outputs.image_tag }} \
            -c runtime_image_ref="${{ steps.build.outputs.image_ref }}" \
            -c model_id="${MODEL_ID:-anthropic.claude-3-5-sonnet-20241022-v2:0}" \
            -c model_arn="${MODEL_ARN:-}" \
            -c pdf_url_expires="${PDF_URL_EXPIRES:-600}"
          # 正式部署所有栈，且关闭人工审批（CI 场景）
          cdk deploy --all --require-approval never \
            -c existing_ecr_repository_name=${{ steps.ecr.outputs.repo_name }} \
            -c runtime_image_tag=${{ steps.build.outputs.image_tag }} \
            -c runtime_image_ref="${{ steps.build.outputs.image_ref }}" \
            -c model_id="${MODEL_ID:-anthropic.claude-3-5-sonnet-20241022-v2:0}" \
            -c model_arn="${MODEL_ARN:-}" \
            -c pdf_url_expires="${PDF_URL_EXPIRES:-600}"

      # 部署后做一次真实调用烟雾测试，验证端到端可用
      - name: Grant smoke invoke permission to deploy role
        env:
          AWS_REGION: ap-northeast-1
          DEPLOY_ROLE_NAME: GitHubActions-Deploy-InfraRole
          BUILT_IMAGE_TAG: ${{ steps.build.outputs.image_tag }}
          BUILT_IMAGE_REF: ${{ steps.build.outputs.image_ref }}
        run: |
          set -euo pipefail
          echo "Smoke is validating runtime image tag: ${BUILT_IMAGE_TAG}"
          echo "Smoke is validating runtime image ref: ${BUILT_IMAGE_REF}"
          STACK_NAME="InfraStack"
          STACK_OUTPUTS="$(aws cloudformation describe-stacks --stack-name "${STACK_NAME}" --query "Stacks[0].Outputs" --output json)"
          RUNTIME_ARN="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeArn") | .OutputValue' | head -n1)"
          ENDPOINT_NAME="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeEndpointName") | .OutputValue' | head -n1)"
          if [ -z "${RUNTIME_ARN}" ] || [ "${RUNTIME_ARN}" = "None" ]; then
            echo "Missing required stack output: AgentRuntimeArn"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          if [ -z "${ENDPOINT_NAME}" ] || [ "${ENDPOINT_NAME}" = "None" ]; then
            echo "Missing required stack output: AgentRuntimeEndpointName"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          ENDPOINT_ARN="${RUNTIME_ARN}/runtime-endpoint/${ENDPOINT_NAME}"
          cat > policy.json <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "AllowInvokeAgentRuntimeSmoke",
                "Effect": "Allow",
                "Action": "bedrock-agentcore:InvokeAgentRuntime",
                "Resource": [
                  "${RUNTIME_ARN}",
                  "${ENDPOINT_ARN}",
                  "${RUNTIME_ARN}/runtime-endpoint/*"
                ]
              },
              {
                "Sid": "AllowReadCloudWatchLogsForSmokeDiagnostics",
                "Effect": "Allow",
                "Action": [
                  "logs:DescribeLogGroups",
                  "logs:DescribeLogStreams",
                  "logs:FilterLogEvents",
                  "logs:GetLogEvents"
                ],
                "Resource": "*"
              }
            ]
          }
          EOF
          aws iam put-role-policy \
            --role-name "${DEPLOY_ROLE_NAME}" \
            --policy-name "AllowInvokeAgentRuntimeSmoke" \
            --policy-document file://policy.json
          # IAM policy propagation can be eventually consistent.
          sleep 10

      - name: Smoke test /invocations
        env:
          AWS_REGION: ap-northeast-1
        run: |
          set -euo pipefail
          # CloudFormation 栈名（与 infra/app.py 中一致）
          STACK_NAME="InfraStack"
          # 读取栈输出（JSON）
          STACK_OUTPUTS="$(aws cloudformation describe-stacks --stack-name "${STACK_NAME}" --query "Stacks[0].Outputs" --output json)"
          # InvokeAgentRuntime 使用 ARN + endpoint qualifier
          RUNTIME_ARN="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeArn") | .OutputValue' | head -n1)"
          ENDPOINT_NAME="$(echo "${STACK_OUTPUTS}" | jq -r '.[] | select(.OutputKey=="AgentRuntimeEndpointName") | .OutputValue' | head -n1)"
          if [ -z "${RUNTIME_ARN}" ] || [ "${RUNTIME_ARN}" = "None" ] || [ -z "${ENDPOINT_NAME}" ] || [ "${ENDPOINT_NAME}" = "None" ]; then
            echo "Missing required stack outputs: AgentRuntimeArn or AgentRuntimeEndpointName"
            echo "${STACK_OUTPUTS}"
            exit 1
          fi
          export RUNTIME_ARN ENDPOINT_NAME
          python - <<'PY'
          import io
          import json
          import os
          import sys
          import time
          from datetime import datetime, timedelta, timezone

          import boto3

          runtime_arn = os.environ["RUNTIME_ARN"]
          endpoint_name = os.environ["ENDPOINT_NAME"]
          region = os.environ["AWS_REGION"]
          payload = {
              "body": {
                  "prompt": "smoke ping",
                  "user_id": "gha",
                  "session_id": "deploy-smoke",
                  "locale": "zh-CN",
              }
          }

          client = boto3.client("bedrock-agentcore", region_name=region)
          logs_client = boto3.client("logs", region_name=region)

          def dump_runtime_start_logs() -> None:
              runtime_id_hint = runtime_arn.rsplit("/", 1)[-1]
              now = datetime.now(timezone.utc)
              start_ms = int((now - timedelta(minutes=20)).timestamp() * 1000)
              end_ms = int(now.timestamp() * 1000)
              try:
                  groups = []
                  paginator = logs_client.get_paginator("describe_log_groups")
                  for page in paginator.paginate():
                      for g in page.get("logGroups", []):
                          name = g.get("logGroupName", "")
                          if (
                              "bedrock" in name.lower()
                              and ("agentcore" in name.lower() or "runtime" in name.lower())
                          ):
                              groups.append(name)
                  if not groups:
                      print("CloudWatch diagnostic: no matching Bedrock/AgentCore log groups found.")
                      return
                  print("CloudWatch diagnostic log groups:")
                  for name in groups[:20]:
                      print(f"  - {name}")
                  for group in groups[:5]:
                      try:
                          events = logs_client.filter_log_events(
                              logGroupName=group,
                              startTime=start_ms,
                              endTime=end_ms,
                              limit=50,
                          ).get("events", [])
                      except Exception as inner_exc:  # noqa: BLE001
                          print(f"CloudWatch diagnostic read failed for {group}: {inner_exc}")
                          continue
                      matched = []
                      for ev in events:
                          msg = ev.get("message", "")
                          if runtime_id_hint in msg or endpoint_name in msg or "error" in msg.lower():
                              matched.append(msg.strip())
                      if matched:
                          print(f"CloudWatch diagnostic events from {group}:")
                          for line in matched[-20:]:
                              print(line)
              except Exception as exc:  # noqa: BLE001
                  print(f"CloudWatch diagnostic failed: {exc}")

          def decode_response_blob(blob: object) -> dict:
              if isinstance(blob, (bytes, bytearray)):
                  raw = bytes(blob).decode("utf-8")
                  return json.loads(raw)
              if hasattr(blob, "read"):
                  raw = blob.read().decode("utf-8")
                  return json.loads(raw)
              if isinstance(blob, io.IOBase):
                  raw = blob.read().decode("utf-8")
                  return json.loads(raw)
              if hasattr(blob, "__iter__"):
                  chunks = []
                  for event in blob:
                      chunk = event.get("chunk") if isinstance(event, dict) else None
                      if isinstance(chunk, dict) and "bytes" in chunk:
                          chunks.append(chunk["bytes"])
                  if chunks:
                      raw = b"".join(chunks).decode("utf-8")
                      return json.loads(raw)
              if isinstance(blob, str):
                  return json.loads(blob)
              raise TypeError(f"Unsupported response payload type: {type(blob)!r}")

          last_error = None
          response_json = None
          for i in range(1, 7):
              try:
                  resp = client.invoke_agent_runtime(
                      agentRuntimeArn=runtime_arn,
                      qualifier=endpoint_name,
                      payload=json.dumps(payload, ensure_ascii=False).encode("utf-8"),
                      contentType="application/json",
                  )
                  response_json = decode_response_blob(resp.get("response"))
                  with open("response.json", "w", encoding="utf-8") as f:
                      json.dump(response_json, f, ensure_ascii=False)
                  break
              except Exception as exc:  # noqa: BLE001
                  last_error = exc
                  print(f"Smoke attempt {i} failed ({exc.__class__.__name__}): {exc}")
                  if i == 6:
                      dump_runtime_start_logs()
                      raise
                  time.sleep(10)

          if response_json is None:
              print(f"Smoke failed without response object, last error: {last_error}")
              sys.exit(1)

          body_obj = response_json.get("body", response_json)
          if isinstance(body_obj, str):
              body_obj = json.loads(body_obj)

          ok_status = ("statusCode" not in response_json) or (response_json.get("statusCode") == 200)
          required = bool(
              isinstance(body_obj, dict)
              and body_obj.get("record_id")
              and body_obj.get("answer")
              and isinstance(body_obj.get("pdf"), dict)
              and body_obj["pdf"].get("s3_key")
              and body_obj["pdf"].get("url")
          )
          if not (ok_status and required):
              print("Smoke response validation failed.")
              print(json.dumps(response_json, ensure_ascii=False, indent=2))
              sys.exit(1)
          PY
